{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0551dd29-9b8b-4565-aa24-68461e487448",
   "metadata": {},
   "source": [
    "## ERA5 Wind Gust Retrieval & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8e2d2-8cb6-4bc2-aa28-2e5b73679bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import imageio.v2 as imageio \n",
    "import io\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948644e0-4232-4eb9-9e41-9e420cb21652",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### USER INPUTS\n",
    "try:\n",
    "    year = int(input(\"ðŸ“… Enter the year (YYYY): \"))\n",
    "    month = int(input(\"ðŸ“… Enter the month (MM): \"))\n",
    "    start_day = int(input(\"ðŸ“… Enter the start day (DD): \"))\n",
    "    end_day = int(input(\"ðŸ“… Enter the end day (DD): \"))\n",
    "except ValueError:\n",
    "    raise ValueError(\"Year, month, and days must be valid numbers!\")\n",
    "\n",
    "# Bounding Box (Latitude Max, Longitude Min, Latitude Min, Longitude Max)\n",
    "try:\n",
    "    print(\"\\n ðŸŒ Enter the bounding box coordinates:\")\n",
    "    lat_max = float(input(\"ðŸ”¼ Latitude Max: \"))\n",
    "    lon_min = float(input(\"â—€ï¸ Longitude Min: \"))\n",
    "    lat_min = float(input(\"ðŸ”½ Latitude Min: \"))\n",
    "    lon_max = float(input(\"â–¶ï¸ Longitude Max: \"))\n",
    "except ValueError:\n",
    "    raise ValueError(\"Latitude and Longitude values must be valid numbers!\")\n",
    "\n",
    "# Validate date range\n",
    "if start_day > end_day or start_day < 1 or end_day > 31:\n",
    "    raise ValueError(\"Invalid date range! Ensure start_day â‰¤ end_day and within valid days.\")\n",
    "\n",
    "# Construct Filename\n",
    "grib_filename = f\"{start_day:02d}_to_{end_day:02d}_{month:02d}{year}_10m_wind_gust.grib\"\n",
    "\n",
    "# DOWNLOAD ERA5 DATA \n",
    "dataset = \"reanalysis-era5-single-levels\"\n",
    "request = {\n",
    "    \"variable\": [\"instantaneous_10m_wind_gust\"],  \n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"year\": [str(year)],  \n",
    "    \"month\": [f\"{month:02d}\"],  \n",
    "    \"day\": [f\"{d:02d}\" for d in range(start_day, end_day + 1)],  # Multiple days as a list\n",
    "    \"time\": [f\"{hour:02d}:00\" for hour in range(24)],  \n",
    "    \"area\": [lat_max, lon_min, lat_min, lon_max],  \n",
    "    \"data_format\": \"grib\"\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "print(f\"\\n Downloading ERA5 Wind Gust Data from {start_day:02d}/{month:02d}/{year} to {end_day:02d}/{month:02d}/{year} :\")\n",
    "client.retrieve(dataset, request).download(grib_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02afd9-7af5-4b38-ac20-1495e72e907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "ds = xr.open_dataset(grib_filename, engine=\"cfgrib\")\n",
    "\n",
    "print(\"Variables present in the GRIB file:\", ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a3363-41ce-4f86-bfde-41c125153c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame & filter NaNs\n",
    "df = ds.to_dataframe().reset_index()\n",
    "df_filtered = df.dropna(subset=[\"i10fg\"]).copy()\n",
    "df_filtered.loc[:, \"valid_time\"] = pd.to_datetime(df_filtered[\"valid_time\"])\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c4f49-099b-4996-a31b-39a8bbf44f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique valid times\n",
    "valid_times = df_filtered[\"valid_time\"].unique()\n",
    "\n",
    "# Construct GIF filename\n",
    "gif_filename = os.path.splitext(grib_filename)[0] + \".gif\"\n",
    "\n",
    "# Generate GIF\n",
    "print(\"\\n Creating GIF visualization ...\")\n",
    "extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "\n",
    "with imageio.get_writer(gif_filename, mode=\"I\", duration=4, loop=0) as writer:\n",
    "    for i, vtime in enumerate(valid_times):\n",
    "        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "        ax.add_feature(cfeature.COASTLINE)\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n",
    "        ax.add_feature(cfeature.LAND, edgecolor=\"black\")\n",
    "\n",
    "        df_time = df_filtered[df_filtered[\"valid_time\"] == vtime]\n",
    "        gust_data = df_time.pivot(index=\"latitude\", columns=\"longitude\", values=\"i10fg\").sort_index(ascending=False)\n",
    "\n",
    "        img = ax.pcolormesh(gust_data.columns, gust_data.index, gust_data.values, cmap=\"coolwarm\", shading=\"auto\", transform=ccrs.PlateCarree())\n",
    "        cbar = plt.colorbar(img, ax=ax, orientation=\"vertical\", label=\"10m Wind Gust (m/s)\")\n",
    "\n",
    "        ax.set_title(f\"Wind Gust at 10m | {vtime.strftime('%Y-%m-%d %H:%M')}\", fontsize=12)\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        buf.seek(0)\n",
    "        image = imageio.imread(buf)\n",
    "        writer.append_data(image)\n",
    "\n",
    "print(f\" GIF saved as: {gif_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea43b09-9349-4a00-9541-031073e3fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display GIF\n",
    "from IPython.display import display, Image\n",
    "display(Image(filename=gif_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf41d06-6b15-4f70-99d1-bfdc701a5102",
   "metadata": {},
   "source": [
    "## Wind Storm Detection & Trajectory Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2cd63b-0dbc-496d-b6d6-dd9efd6917c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label, center_of_mass, find_objects\n",
    "from shapely.geometry import LineString, Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faaec6f-879a-40fb-af9d-ee64d5a144bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VENT_MIN = 24.7  # Seuil minimal de vitesse du vent (en m/s)\n",
    "SURFACE_MIN = 50  # Seuil minimum de surface (en kmÂ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18c0e7-16d1-4912-8d01-10f9449c7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spatial resolution\n",
    "latitudes = ds.latitude.values\n",
    "longitudes = ds.longitude.values\n",
    "\n",
    "if len(latitudes) > 1 and len(longitudes) > 1:\n",
    "    resolution_km = geodesic((latitudes[0], longitudes[0]), (latitudes[1], longitudes[0])).kilometers\n",
    "    RESOLUTION_KM2 = resolution_km ** 2\n",
    "else:\n",
    "    RESOLUTION_KM2 = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52a161-d694-4aae-a2a8-8c6d30964e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "# Smooth storm trajectory using B-Spline interpolation\n",
    "def smooth_trajectory(line, smoothing_factor=0.5):\n",
    "    if len(line.coords) < 4:  # Must have at least 4 points for B-spline \n",
    "        print(\"Not enough points for smoothing, returning original trajectory.\")\n",
    "        return line  \n",
    "\n",
    "    # Remove duplicate consecutive points\n",
    "    unique_coords = []\n",
    "    for i, coord in enumerate(line.coords):\n",
    "        if i == 0 or coord != line.coords[i - 1]:  # Only keep unique consecutive points\n",
    "            unique_coords.append(coord)\n",
    "\n",
    "    if len(unique_coords) < 4:  # Ensure enough unique points for B-spline\n",
    "        print(\"Not enough unique points for smoothing, returning original trajectory.\")\n",
    "        return LineString(unique_coords)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    x, y = zip(*unique_coords)\n",
    "    x, y = np.array(x), np.array(y)\n",
    "\n",
    "    # Check for invalid values\n",
    "    if np.any(np.isnan(x)) or np.any(np.isnan(y)) or np.any(np.isinf(x)) or np.any(np.isinf(y)):\n",
    "        print(\"Invalid coordinates detected, returning original trajectory.\")\n",
    "        return line\n",
    "\n",
    "    # Create a B-Spline curve\n",
    "    try:\n",
    "        tck, u = splprep([x, y], s=smoothing_factor, k=3)  # Ensure valid smoothing\n",
    "        u_fine = np.linspace(0, 1, len(x) * 10)  # More points for a smooth curve\n",
    "        x_smooth, y_smooth = splev(u_fine, tck)\n",
    "\n",
    "        return LineString(zip(x_smooth, y_smooth))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Spline interpolation failed: {e}, returning original trajectory.\")\n",
    "        return line\n",
    "\n",
    "\n",
    "# Detect high wind-speed areas, extract storm centroids, and track their movement over time\n",
    "def detect_wind_clusters(ds):\n",
    "    points = []  \n",
    "    all_points = []  \n",
    "    linestrings = []  \n",
    "    surfaces = []  \n",
    "\n",
    "    time_values = ds.time.values  \n",
    "    step_values = ds.step.values\n",
    "\n",
    "    for base_time in time_values:\n",
    "        for step in step_values:\n",
    "            step_timedelta = pd.to_timedelta(step)\n",
    "            datatime = pd.to_datetime(base_time) + step_timedelta\n",
    "\n",
    "            print(f\"Processing time step: {datatime}\")\n",
    "\n",
    "            # Extract wind speed data\n",
    "            wind_speed = ds[\"i10fg\"].sel(time=base_time, step=step).values\n",
    "            mask = wind_speed >= VENT_MIN\n",
    "            labeled_array, num_features = label(mask)\n",
    "\n",
    "            # Extract storm regions\n",
    "            regions = find_objects(labeled_array)\n",
    "\n",
    "            max_area = 0\n",
    "            best_centroid = None\n",
    "\n",
    "            for i, region_slice in enumerate(regions, start=1):\n",
    "                if region_slice is None:\n",
    "                    continue  \n",
    "\n",
    "                region = labeled_array[region_slice] == i\n",
    "                area = np.sum(region) * RESOLUTION_KM2\n",
    "\n",
    "                if area >= SURFACE_MIN:\n",
    "                    y_start, y_end = region_slice[0].start, region_slice[0].stop\n",
    "                    x_start, x_end = region_slice[1].start, region_slice[1].stop\n",
    "\n",
    "                    coords = [(longitudes[x], latitudes[y]) \n",
    "                              for y in range(y_start, y_end) \n",
    "                              for x in range(x_start, x_end) if region[y - y_start, x - x_start]]\n",
    "\n",
    "                    coords = list(set(coords))  \n",
    "                    coords.append(coords[0])  \n",
    "\n",
    "                    if len(coords) >= 4:\n",
    "                        polygon = Polygon(coords)\n",
    "                        surfaces.append({\"datetime\": datatime, \"geometry\": polygon, \"surface_area\": area})\n",
    "\n",
    "                    # Compute centroid for the largest storm area\n",
    "                    if area > max_area:\n",
    "                        y, x = center_of_mass(region)\n",
    "                        best_centroid = Point(longitudes[int(x_start + x)], latitudes[int(y_start + y)])\n",
    "                        max_area = area\n",
    "\n",
    "            if best_centroid:\n",
    "                if len(points) > 0:\n",
    "                    last_point = points[-1]\n",
    "\n",
    "                    # Compute distance between last point and new centroid\n",
    "                    distance = geodesic((last_point[\"geometry\"].y, last_point[\"geometry\"].x), \n",
    "                                        (best_centroid.y, best_centroid.x)).kilometers\n",
    "\n",
    "                    if distance > 300:  # Threshold for separating trajectories\n",
    "                        print(f\"Storm shift detected ({distance:.2f} km), starting new trajectory.\")\n",
    "\n",
    "                        # Save previous storm's centroids before resetting points\n",
    "                        all_points.extend(points)  \n",
    "\n",
    "                        # Save previous trajectory if it has more than one point and apply smoothing\n",
    "                        if len(points) > 1:\n",
    "                            sorted_points = sorted(points, key=lambda p: p[\"datetime\"])\n",
    "                            raw_line = LineString([p[\"geometry\"] for p in sorted_points])\n",
    "                            smoothed_line = smooth_trajectory(raw_line, smoothing_factor=0.01) \n",
    "                            linestrings.append({\"geometry\": smoothed_line})\n",
    "\n",
    "                        # Start a new trajectory\n",
    "                        points = []\n",
    "\n",
    "                # Append centroid to trajectory without filtering duplicates\n",
    "                points.append({\"datetime\": datatime, \"geometry\": best_centroid})\n",
    "                print(f\" Centroid recorded at {datatime}: {best_centroid}, Area: {max_area:.2f} kmÂ²\")\n",
    "\n",
    "    # Save last storm's centroids\n",
    "    all_points.extend(points)\n",
    "\n",
    "    # Save the last trajectory\n",
    "    if len(points) > 1:\n",
    "        sorted_points = sorted(points, key=lambda p: p[\"datetime\"])\n",
    "        raw_line = LineString([p[\"geometry\"] for p in sorted_points])\n",
    "        smoothed_line = smooth_trajectory(raw_line, smoothing_factor=0.01)  \n",
    "        linestrings.append({\"geometry\": smoothed_line})\n",
    "\n",
    "    return all_points, linestrings, surfaces  \n",
    "\n",
    "# Run storm detection\n",
    "points, lines, surfaces = detect_wind_clusters(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ba0df-4bae-46f6-ae60-819056e46a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "def export_to_shapefile(data, output_path):\n",
    "    if not data:\n",
    "        print(f\"No data available for export: {output_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert Data to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(data, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Convert datetime column to string format if it exists\n",
    "    if \"datetime\" in gdf.columns:\n",
    "        gdf[\"datetime\"] = gdf[\"datetime\"].astype(str)  \n",
    "\n",
    "    # Rename 'surface_area' to 'area' if present\n",
    "    if \"surface_area\" in gdf.columns:\n",
    "        gdf = gdf.rename(columns={\"surface_area\": \"area\"})  \n",
    "\n",
    "    # Export to shapefile\n",
    "    gdf.to_file(output_path)\n",
    "    print(f\"Export successful: {output_path}\")\n",
    "\n",
    "# Use the actual GRIB filename for naming\n",
    "file_name = os.path.splitext(os.path.basename(grib_filename))[0]\n",
    "wind_threshold = f\"_V{VENT_MIN}\"\n",
    "area_threshold = f\"_S{SURFACE_MIN}\"\n",
    "\n",
    "# Export shapefiles\n",
    "export_to_shapefile(points, f\"WC_{file_name}{wind_threshold}{area_threshold}.shp\")  # Wind Centroids\n",
    "export_to_shapefile(lines, f\"WT_{file_name}{wind_threshold}{area_threshold}.shp\")  # Wind Trajectories\n",
    "export_to_shapefile(surfaces, f\"WS_{file_name}{wind_threshold}{area_threshold}.shp\")  # Wind Surfaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6c065-33ce-4cbd-b217-44fc105febdf",
   "metadata": {},
   "source": [
    "## Interactive Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c4409-7645-4f4f-a507-68b477b57a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Marker, Popup, Polyline, Polygon, LayerGroup, TileLayer, basemaps, basemap_to_tiles, LayersControl, CircleMarker\n",
    "from ipywidgets import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e6d28-ed90-44a0-a374-645d941ecd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the map\n",
    "center = [(lat_min + lat_max) / 2, (lon_min + lon_max) / 2]\n",
    "m = Map(center=center, zoom=6, basemap=basemap_to_tiles(basemaps.Esri.WorldImagery))\n",
    "\n",
    "# Define layers\n",
    "trajectory_layer = LayerGroup(name=\"Trajectories\")\n",
    "surface_layer = LayerGroup(name=\"Surfaces\")\n",
    "centroid_layer = LayerGroup(name=\"Centroids\")\n",
    "\n",
    "# Add trajectories\n",
    "for line in lines:\n",
    "    polyline = Polyline(\n",
    "        locations=[(coord[1], coord[0]) for coord in line[\"geometry\"].coords], \n",
    "        color=\"red\",\n",
    "        weight=2,  \n",
    "        opacity=1.0,  \n",
    "        fill=False,   \n",
    "        name=\"Trajectory\",\n",
    "    )\n",
    "    trajectory_layer.add_layer(polyline)\n",
    "\n",
    "# Add surfaces\n",
    "for surface in surfaces:\n",
    "    polygon = Polygon(\n",
    "        locations=[(coord[1], coord[0]) for coord in surface['geometry'].exterior.coords],\n",
    "        color=\"blue\",\n",
    "        fill_color=\"blue\",\n",
    "        weight=1,\n",
    "        opacity=0.5,\n",
    "        name=\"Surface\"\n",
    "    )\n",
    "    surface_layer.add_layer(polygon)\n",
    "\n",
    "# Add centroids\n",
    "for point in points:\n",
    "    location = (point['geometry'].y, point['geometry'].x)\n",
    "    \n",
    "    # Create a Circlemarker for each centroid\n",
    "    marker = CircleMarker(\n",
    "        location=location,\n",
    "        radius=1,\n",
    "        color=\"yellow\",\n",
    "        fill_color=\"yellow\",\n",
    "        fill_opacity=1,\n",
    "        draggable=False\n",
    "    )\n",
    "    \n",
    "    popup_content = HTML(f\"<b>Datetime:</b> {point['datetime']}<br><b>Location:</b> {location}\")\n",
    "    \n",
    "    marker.popup = popup_content\n",
    "    \n",
    "    centroid_layer.add_layer(marker)\n",
    "\n",
    "# Add layer groups to the map\n",
    "m.add_layer(trajectory_layer)\n",
    "m.add_layer(surface_layer)\n",
    "m.add_layer(centroid_layer)\n",
    "\n",
    "# Add layer control\n",
    "layer_control = LayersControl(position=\"topright\")\n",
    "m.add_control(layer_control)\n",
    "\n",
    "# Display the map\n",
    "display(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b444bd3-f16f-439c-928d-29cd1cfaa488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e01b4729-d984-43c0-a6bd-c618467eb498",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
